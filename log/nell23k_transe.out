2023-04-21 08:20:27,299 - [INFO] - {'name': 'nell23k_transe', 'dataset': 'NELL23K', 'model': 'hogrn', 'score_func': 'transe', 'opn': 'mult', 'batch_size': 128, 'max_epochs': 9999, 'gamma': 40, 'gpu': '0', 'l2': 0, 'lr': 0.001, 'lbl_smooth': 0.1, 'num_workers': 2, 'seed': 41504, 'restore': False, 'bias': False, 'rel_reason': True, 'pre_reason': False, 'reason_type': 'mixdrop', 'act_type': 'tanh', 'rel_norm': True, 'init_dim': 100, 'gcn_dim': 100, 'embed_dim': 100, 'gcn_layer': 1, 'dropout': 0.2, 'hid_drop': 0.2, 'relmix_dim': 200, 'chamix_dim': 200, 'rel_mask': 0, 'chan_drop': 0.1, 'edge_drop': 0, 'temperature': 1, 'sim_decay': 1e-05, 'rel_drop': 0, 'hid_drop2': 0.3, 'feat_drop': 0.3, 'k_w': 10, 'k_h': 10, 'num_filt': 32, 'ker_sz': 3, 'log_dir': './log/', 'config_dir': './config/'}
{'act_type': 'tanh',
 'batch_size': 128,
 'bias': False,
 'chamix_dim': 200,
 'chan_drop': 0.1,
 'config_dir': './config/',
 'dataset': 'NELL23K',
 'dropout': 0.2,
 'edge_drop': 0,
 'embed_dim': 100,
 'feat_drop': 0.3,
 'gamma': 40,
 'gcn_dim': 100,
 'gcn_layer': 1,
 'gpu': '0',
 'hid_drop': 0.2,
 'hid_drop2': 0.3,
 'init_dim': 100,
 'k_h': 10,
 'k_w': 10,
 'ker_sz': 3,
 'l2': 0,
 'lbl_smooth': 0.1,
 'log_dir': './log/',
 'lr': 0.001,
 'max_epochs': 9999,
 'model': 'hogrn',
 'name': 'nell23k_transe',
 'num_filt': 32,
 'num_workers': 2,
 'opn': 'mult',
 'pre_reason': False,
 'reason_type': 'mixdrop',
 'rel_drop': 0,
 'rel_mask': 0,
 'rel_norm': True,
 'rel_reason': True,
 'relmix_dim': 200,
 'restore': False,
 'score_func': 'transe',
 'seed': 41504,
 'sim_decay': 1e-05,
 'temperature': 1}
Dataset:  NELL23K
NUM_ENT:  22925
NUM_REL:  200
Model have 2.5370M paramerters in total
########
2023-04-21 08:20:44,958 - [INFO] - [Epoch:0]:  Training Loss:0.02436

Time cost in one epoch for training: 0.2387s
########
2023-04-21 08:20:59,392 - [INFO] - [Epoch:1]:  Training Loss:0.02427

Time cost in one epoch for training: 0.2406s
########
2023-04-21 08:21:13,755 - [INFO] - [Epoch:2]:  Training Loss:0.02417

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:21:28,097 - [INFO] - [Epoch:3]:  Training Loss:0.02406

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:21:42,434 - [INFO] - [Epoch:4]:  Training Loss:0.02386

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:21:56,973 - [INFO] - [Epoch:5]:  Training Loss:0.02355

Time cost in one epoch for training: 0.2423s
########
2023-04-21 08:22:11,285 - [INFO] - [Epoch:6]:  Training Loss:0.02346

Time cost in one epoch for training: 0.2385s
########
2023-04-21 08:22:25,610 - [INFO] - [Epoch:7]:  Training Loss:0.02336

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:22:39,945 - [INFO] - [Epoch:8]:  Training Loss:0.02323

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:22:54,287 - [INFO] - [Epoch:9]:  Training Loss:0.02314

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:23:08,613 - [INFO] - [Epoch:10]:  Training Loss:0.02312

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:23:22,976 - [INFO] - [Epoch:11]:  Training Loss:0.02309

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:23:37,378 - [INFO] - [Epoch:12]:  Training Loss:0.02306

Time cost in one epoch for training: 0.2400s
########
2023-04-21 08:23:51,791 - [INFO] - [Epoch:13]:  Training Loss:0.02302

Time cost in one epoch for training: 0.2402s
########
2023-04-21 08:24:06,200 - [INFO] - [Epoch:14]:  Training Loss:0.02302

Time cost in one epoch for training: 0.2401s
########
2023-04-21 08:24:20,446 - [INFO] - [Epoch:15]:  Training Loss:0.02292

Time cost in one epoch for training: 0.2374s
########
2023-04-21 08:24:34,816 - [INFO] - [Epoch:16]:  Training Loss:0.02287

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:24:49,171 - [INFO] - [Epoch:17]:  Training Loss:0.0228

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:25:03,538 - [INFO] - [Epoch:18]:  Training Loss:0.02274

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:25:17,850 - [INFO] - [Epoch:19]:  Training Loss:0.02269

Time cost in one epoch for training: 0.2385s
########
2023-04-21 08:25:32,165 - [INFO] - [Epoch:20]:  Training Loss:0.02266

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:25:46,798 - [INFO] - [Epoch:21]:  Training Loss:0.02259

Time cost in one epoch for training: 0.2439s
########
2023-04-21 08:26:01,183 - [INFO] - [Epoch:22]:  Training Loss:0.0225

Time cost in one epoch for training: 0.2397s
########
2023-04-21 08:26:15,502 - [INFO] - [Epoch:23]:  Training Loss:0.02242

Time cost in one epoch for training: 0.2387s
########
2023-04-21 08:26:29,828 - [INFO] - [Epoch:24]:  Training Loss:0.02239

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:26:44,121 - [INFO] - [Epoch:25]:  Training Loss:0.02234

Time cost in one epoch for training: 0.2382s
########
2023-04-21 08:26:58,465 - [INFO] - [Epoch:26]:  Training Loss:0.02228

Time cost in one epoch for training: 0.2391s
########
2023-04-21 08:27:12,759 - [INFO] - [Epoch:27]:  Training Loss:0.02223

Time cost in one epoch for training: 0.2382s
########
2023-04-21 08:27:27,112 - [INFO] - [Epoch:28]:  Training Loss:0.02217

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:27:41,445 - [INFO] - [Epoch:29]:  Training Loss:0.02214

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:27:55,797 - [INFO] - [Epoch:30]:  Training Loss:0.0221

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:28:10,132 - [INFO] - [Epoch:31]:  Training Loss:0.02202

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:28:24,384 - [INFO] - [Epoch:32]:  Training Loss:0.02194

Time cost in one epoch for training: 0.2375s
########
2023-04-21 08:28:38,766 - [INFO] - [Epoch:33]:  Training Loss:0.02187

Time cost in one epoch for training: 0.2397s
########
2023-04-21 08:28:53,118 - [INFO] - [Epoch:34]:  Training Loss:0.02183

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:29:07,434 - [INFO] - [Epoch:35]:  Training Loss:0.02179

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:29:21,768 - [INFO] - [Epoch:36]:  Training Loss:0.02172

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:29:36,083 - [INFO] - [Epoch:37]:  Training Loss:0.02167

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:29:50,449 - [INFO] - [Epoch:38]:  Training Loss:0.02166

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:30:04,840 - [INFO] - [Epoch:39]:  Training Loss:0.02164

Time cost in one epoch for training: 0.2398s
########
2023-04-21 08:30:19,241 - [INFO] - [Epoch:40]:  Training Loss:0.02161

Time cost in one epoch for training: 0.2400s
########
2023-04-21 08:30:33,703 - [INFO] - [Epoch:41]:  Training Loss:0.02158

Time cost in one epoch for training: 0.2410s
########
2023-04-21 08:30:48,150 - [INFO] - [Epoch:42]:  Training Loss:0.02155

Time cost in one epoch for training: 0.2408s
########
2023-04-21 08:31:02,501 - [INFO] - [Epoch:43]:  Training Loss:0.02152

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:31:16,884 - [INFO] - [Epoch:44]:  Training Loss:0.02149

Time cost in one epoch for training: 0.2397s
########
2023-04-21 08:31:31,275 - [INFO] - [Epoch:45]:  Training Loss:0.02145

Time cost in one epoch for training: 0.2398s
########
2023-04-21 08:31:45,654 - [INFO] - [Epoch:46]:  Training Loss:0.02143

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:32:00,091 - [INFO] - [Epoch:47]:  Training Loss:0.02139

Time cost in one epoch for training: 0.2406s
########
2023-04-21 08:32:14,473 - [INFO] - [Epoch:48]:  Training Loss:0.02139

Time cost in one epoch for training: 0.2397s
########
2023-04-21 08:32:28,815 - [INFO] - [Epoch:49]:  Training Loss:0.02135

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:32:43,178 - [INFO] - [Epoch:50]:  Training Loss:0.02132

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:32:56,695 - [INFO] - [Epoch:51]:  Training Loss:0.02128

Time cost in one epoch for training: 0.2253s
########
2023-04-21 08:33:11,033 - [INFO] - [Epoch:52]:  Training Loss:0.02126

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:33:25,369 - [INFO] - [Epoch:53]:  Training Loss:0.02124

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:33:39,738 - [INFO] - [Epoch:54]:  Training Loss:0.02121

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:33:54,223 - [INFO] - [Epoch:55]:  Training Loss:0.02117

Time cost in one epoch for training: 0.2414s
########
2023-04-21 08:34:08,619 - [INFO] - [Epoch:56]:  Training Loss:0.02117

Time cost in one epoch for training: 0.2399s
########
2023-04-21 08:34:23,137 - [INFO] - [Epoch:57]:  Training Loss:0.02117

Time cost in one epoch for training: 0.2420s
########
2023-04-21 08:34:37,452 - [INFO] - [Epoch:58]:  Training Loss:0.02117

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:34:51,702 - [INFO] - [Epoch:59]:  Training Loss:0.02114

Time cost in one epoch for training: 0.2375s
########
2023-04-21 08:35:05,993 - [INFO] - [Epoch:60]:  Training Loss:0.02112

Time cost in one epoch for training: 0.2382s
########
2023-04-21 08:35:20,347 - [INFO] - [Epoch:61]:  Training Loss:0.02112

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:35:34,683 - [INFO] - [Epoch:62]:  Training Loss:0.02111

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:35:49,022 - [INFO] - [Epoch:63]:  Training Loss:0.0211

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:36:03,364 - [INFO] - [Epoch:64]:  Training Loss:0.02108

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:36:17,544 - [INFO] - [Epoch:65]:  Training Loss:0.02108

Time cost in one epoch for training: 0.2363s
########
2023-04-21 08:36:31,835 - [INFO] - [Epoch:66]:  Training Loss:0.02106

Time cost in one epoch for training: 0.2382s
########
2023-04-21 08:36:46,167 - [INFO] - [Epoch:67]:  Training Loss:0.02107

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:36:59,033 - [INFO] - [Epoch:68]:  Training Loss:0.02106

Time cost in one epoch for training: 0.2144s
########
2023-04-21 08:37:13,268 - [INFO] - [Epoch:69]:  Training Loss:0.02105

Time cost in one epoch for training: 0.2372s
########
2023-04-21 08:37:27,618 - [INFO] - [Epoch:70]:  Training Loss:0.02105

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:37:41,938 - [INFO] - [Epoch:71]:  Training Loss:0.02104

Time cost in one epoch for training: 0.2387s
########
2023-04-21 08:37:56,238 - [INFO] - [Epoch:72]:  Training Loss:0.02104

Time cost in one epoch for training: 0.2383s
########
2023-04-21 08:38:10,579 - [INFO] - [Epoch:73]:  Training Loss:0.02107

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:38:24,979 - [INFO] - [Epoch:74]:  Training Loss:0.02104

Time cost in one epoch for training: 0.2400s
########
2023-04-21 08:38:39,139 - [INFO] - [Epoch:75]:  Training Loss:0.02103

Time cost in one epoch for training: 0.2360s
########
2023-04-21 08:38:53,605 - [INFO] - [Epoch:76]:  Training Loss:0.02103

Time cost in one epoch for training: 0.2411s
########
2023-04-21 08:39:07,981 - [INFO] - [Epoch:77]:  Training Loss:0.02101

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:39:22,619 - [INFO] - [Epoch:78]:  Training Loss:0.02101

Time cost in one epoch for training: 0.2440s
########
2023-04-21 08:39:37,039 - [INFO] - [Epoch:79]:  Training Loss:0.021

Time cost in one epoch for training: 0.2403s
########
2023-04-21 08:39:51,417 - [INFO] - [Epoch:80]:  Training Loss:0.021

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:40:05,785 - [INFO] - [Epoch:81]:  Training Loss:0.02099

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:40:20,126 - [INFO] - [Epoch:82]:  Training Loss:0.02099

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:40:34,464 - [INFO] - [Epoch:83]:  Training Loss:0.02099

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:40:48,407 - [INFO] - [Epoch:84]:  Training Loss:0.02098

Time cost in one epoch for training: 0.2324s
########
2023-04-21 08:41:02,746 - [INFO] - [Epoch:85]:  Training Loss:0.02098

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:41:17,075 - [INFO] - [Epoch:86]:  Training Loss:0.02099

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:41:31,419 - [INFO] - [Epoch:87]:  Training Loss:0.02098

Time cost in one epoch for training: 0.2391s
########
2023-04-21 08:41:45,758 - [INFO] - [Epoch:88]:  Training Loss:0.02097

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:42:00,154 - [INFO] - [Epoch:89]:  Training Loss:0.02096

Time cost in one epoch for training: 0.2399s
########
2023-04-21 08:42:14,531 - [INFO] - [Epoch:90]:  Training Loss:0.02096

Time cost in one epoch for training: 0.2397s
########
2023-04-21 08:42:28,237 - [INFO] - [Epoch:91]:  Training Loss:0.02096

Time cost in one epoch for training: 0.2284s
########
2023-04-21 08:42:41,574 - [INFO] - [Epoch:92]:  Training Loss:0.02096

Time cost in one epoch for training: 0.2223s
########
2023-04-21 08:42:55,943 - [INFO] - [Epoch:93]:  Training Loss:0.02096

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:43:10,238 - [INFO] - [Epoch:94]:  Training Loss:0.02095

Time cost in one epoch for training: 0.2383s
########
2023-04-21 08:43:24,595 - [INFO] - [Epoch:95]:  Training Loss:0.02094

Time cost in one epoch for training: 0.2393s
########
2023-04-21 08:43:38,874 - [INFO] - [Epoch:96]:  Training Loss:0.02093

Time cost in one epoch for training: 0.2380s
########
2023-04-21 08:43:53,247 - [INFO] - [Epoch:97]:  Training Loss:0.02093

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:44:07,754 - [INFO] - [Epoch:98]:  Training Loss:0.02096

Time cost in one epoch for training: 0.2418s
########
2023-04-21 08:44:22,129 - [INFO] - [Epoch:99]:  Training Loss:0.02094

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:44:35,755 - [INFO] - [Epoch:100]:  Training Loss:0.02092

Time cost in one epoch for training: 0.2271s
########
2023-04-21 08:44:49,682 - [INFO] - [Epoch:101]:  Training Loss:0.02091

Time cost in one epoch for training: 0.2321s
########
2023-04-21 08:45:04,057 - [INFO] - [Epoch:102]:  Training Loss:0.02092

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:45:18,419 - [INFO] - [Epoch:103]:  Training Loss:0.02092

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:45:32,759 - [INFO] - [Epoch:104]:  Training Loss:0.02091

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:45:47,071 - [INFO] - [Epoch:105]:  Training Loss:0.0209

Time cost in one epoch for training: 0.2385s
########
2023-04-21 08:46:01,305 - [INFO] - [Epoch:106]:  Training Loss:0.02089

Time cost in one epoch for training: 0.2372s
########
2023-04-21 08:46:15,645 - [INFO] - [Epoch:107]:  Training Loss:0.02088

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:46:29,959 - [INFO] - [Epoch:108]:  Training Loss:0.02088

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:46:44,292 - [INFO] - [Epoch:109]:  Training Loss:0.02088

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:46:58,654 - [INFO] - [Epoch:110]:  Training Loss:0.02087

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:47:13,014 - [INFO] - [Epoch:111]:  Training Loss:0.02086

Time cost in one epoch for training: 0.2393s
########
2023-04-21 08:47:27,362 - [INFO] - [Epoch:112]:  Training Loss:0.02086

Time cost in one epoch for training: 0.2391s
########
2023-04-21 08:47:41,689 - [INFO] - [Epoch:113]:  Training Loss:0.02085

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:47:56,028 - [INFO] - [Epoch:114]:  Training Loss:0.02085

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:48:10,386 - [INFO] - [Epoch:115]:  Training Loss:0.02084

Time cost in one epoch for training: 0.2393s
########
2023-04-21 08:48:24,756 - [INFO] - [Epoch:116]:  Training Loss:0.02084

Time cost in one epoch for training: 0.2395s
########
2023-04-21 08:48:39,093 - [INFO] - [Epoch:117]:  Training Loss:0.02083

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:48:53,456 - [INFO] - [Epoch:118]:  Training Loss:0.02083

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:49:07,792 - [INFO] - [Epoch:119]:  Training Loss:0.02083

Time cost in one epoch for training: 0.2389s
########
2023-04-21 08:49:22,120 - [INFO] - [Epoch:120]:  Training Loss:0.02082

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:49:36,439 - [INFO] - [Epoch:121]:  Training Loss:0.02081

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:49:50,757 - [INFO] - [Epoch:122]:  Training Loss:0.02081

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:50:05,099 - [INFO] - [Epoch:123]:  Training Loss:0.02081

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:50:19,429 - [INFO] - [Epoch:124]:  Training Loss:0.0208

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:50:33,740 - [INFO] - [Epoch:125]:  Training Loss:0.02079

Time cost in one epoch for training: 0.2385s
########
2023-04-21 08:50:47,879 - [INFO] - [Epoch:126]:  Training Loss:0.02079

Time cost in one epoch for training: 0.2357s
########
2023-04-21 08:51:02,315 - [INFO] - [Epoch:127]:  Training Loss:0.02079

Time cost in one epoch for training: 0.2406s
########
2023-04-21 08:51:16,626 - [INFO] - [Epoch:128]:  Training Loss:0.02078

Time cost in one epoch for training: 0.2385s
########
2023-04-21 08:51:31,159 - [INFO] - [Epoch:129]:  Training Loss:0.02077

Time cost in one epoch for training: 0.2422s
########
2023-04-21 08:51:45,488 - [INFO] - [Epoch:130]:  Training Loss:0.02077

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:51:59,863 - [INFO] - [Epoch:131]:  Training Loss:0.02076

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:52:14,165 - [INFO] - [Epoch:132]:  Training Loss:0.02076

Time cost in one epoch for training: 0.2384s
########
2023-04-21 08:52:28,518 - [INFO] - [Epoch:133]:  Training Loss:0.02076

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:52:41,608 - [INFO] - [Epoch:134]:  Training Loss:0.02075

Time cost in one epoch for training: 0.2182s
########
2023-04-21 08:52:55,963 - [INFO] - [Epoch:135]:  Training Loss:0.02075

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:53:10,247 - [INFO] - [Epoch:136]:  Training Loss:0.02074

Time cost in one epoch for training: 0.2380s
########
2023-04-21 08:53:24,529 - [INFO] - [Epoch:137]:  Training Loss:0.02074

Time cost in one epoch for training: 0.2381s
########
2023-04-21 08:53:38,906 - [INFO] - [Epoch:138]:  Training Loss:0.02073

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:53:53,261 - [INFO] - [Epoch:139]:  Training Loss:0.02073

Time cost in one epoch for training: 0.2392s
########
2023-04-21 08:54:07,641 - [INFO] - [Epoch:140]:  Training Loss:0.02073

Time cost in one epoch for training: 0.2396s
########
2023-04-21 08:54:21,935 - [INFO] - [Epoch:141]:  Training Loss:0.02073

Time cost in one epoch for training: 0.2383s
########
2023-04-21 08:54:36,299 - [INFO] - [Epoch:142]:  Training Loss:0.02072

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:54:50,621 - [INFO] - [Epoch:143]:  Training Loss:0.02072

Time cost in one epoch for training: 0.2387s
########
2023-04-21 08:55:04,980 - [INFO] - [Epoch:144]:  Training Loss:0.02071

Time cost in one epoch for training: 0.2393s
########
2023-04-21 08:55:19,337 - [INFO] - [Epoch:145]:  Training Loss:0.02071

Time cost in one epoch for training: 0.2393s
########
2023-04-21 08:55:33,446 - [INFO] - [Epoch:146]:  Training Loss:0.0207

Time cost in one epoch for training: 0.2351s
########
2023-04-21 08:55:47,450 - [INFO] - [Epoch:147]:  Training Loss:0.0207

Time cost in one epoch for training: 0.2334s
########
2023-04-21 08:56:01,768 - [INFO] - [Epoch:148]:  Training Loss:0.0207

Time cost in one epoch for training: 0.2386s
########
2023-04-21 08:56:16,033 - [INFO] - [Epoch:149]:  Training Loss:0.0207

Time cost in one epoch for training: 0.2377s
########
2023-04-21 08:56:30,427 - [INFO] - [Epoch:150]:  Training Loss:0.0207

Time cost in one epoch for training: 0.2399s
########
2023-04-21 08:56:44,697 - [INFO] - [Epoch:151]:  Training Loss:0.02069

Time cost in one epoch for training: 0.2378s
########
2023-04-21 08:56:59,026 - [INFO] - [Epoch:152]:  Training Loss:0.02069

Time cost in one epoch for training: 0.2388s
########
2023-04-21 08:57:13,389 - [INFO] - [Epoch:153]:  Training Loss:0.02069

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:57:27,753 - [INFO] - [Epoch:154]:  Training Loss:0.02069

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:57:42,117 - [INFO] - [Epoch:155]:  Training Loss:0.02069

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:57:56,389 - [INFO] - [Epoch:156]:  Training Loss:0.02068

Time cost in one epoch for training: 0.2379s
########
2023-04-21 08:58:10,710 - [INFO] - [Epoch:157]:  Training Loss:0.02068

Time cost in one epoch for training: 0.2387s
########
2023-04-21 08:58:25,051 - [INFO] - [Epoch:158]:  Training Loss:0.02068

Time cost in one epoch for training: 0.2390s
########
2023-04-21 08:58:39,416 - [INFO] - [Epoch:159]:  Training Loss:0.02068

Time cost in one epoch for training: 0.2394s
########
2023-04-21 08:58:53,825 - [INFO] - [Epoch:160]:  Training Loss:0.02068

Time cost in one epoch for training: 0.2402s
########
2023-04-21 08:59:08,219 - [INFO] - [Epoch:161]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2399s
########
2023-04-21 08:59:22,599 - [INFO] - [Epoch:162]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2397s
########
2023-04-21 08:59:37,011 - [INFO] - [Epoch:163]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2402s
########
2023-04-21 08:59:51,448 - [INFO] - [Epoch:164]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2406s
########
2023-04-21 09:00:05,899 - [INFO] - [Epoch:165]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2408s
########
2023-04-21 09:00:20,162 - [INFO] - [Epoch:166]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2377s
########
2023-04-21 09:00:34,520 - [INFO] - [Epoch:167]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2393s
########
2023-04-21 09:00:48,859 - [INFO] - [Epoch:168]:  Training Loss:0.02067

Time cost in one epoch for training: 0.2390s
########
2023-04-21 09:01:03,271 - [INFO] - [Epoch:169]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2402s
########
2023-04-21 09:01:17,617 - [INFO] - [Epoch:170]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2391s
########
2023-04-21 09:01:31,981 - [INFO] - [Epoch:171]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2394s
########
2023-04-21 09:01:46,273 - [INFO] - [Epoch:172]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2382s
########
2023-04-21 09:02:00,597 - [INFO] - [Epoch:173]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2387s
########
2023-04-21 09:02:14,968 - [INFO] - [Epoch:174]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2395s
########
2023-04-21 09:02:29,337 - [INFO] - [Epoch:175]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2395s
########
2023-04-21 09:02:43,841 - [INFO] - [Epoch:176]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2417s
########
2023-04-21 09:02:58,224 - [INFO] - [Epoch:177]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2397s
########
2023-04-21 09:03:12,552 - [INFO] - [Epoch:178]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2388s
########
2023-04-21 09:03:26,910 - [INFO] - [Epoch:179]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2393s
########
2023-04-21 09:03:41,300 - [INFO] - [Epoch:180]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2398s
########
2023-04-21 09:03:55,655 - [INFO] - [Epoch:181]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2393s
########
2023-04-21 09:04:10,018 - [INFO] - [Epoch:182]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2394s
########
2023-04-21 09:04:24,404 - [INFO] - [Epoch:183]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2398s
########
2023-04-21 09:04:38,767 - [INFO] - [Epoch:184]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2394s
########
2023-04-21 09:04:53,134 - [INFO] - [Epoch:185]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2394s
########
2023-04-21 09:05:06,942 - [INFO] - [Epoch:186]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2301s
########
2023-04-21 09:05:21,294 - [INFO] - [Epoch:187]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2392s
########
2023-04-21 09:05:35,682 - [INFO] - [Epoch:188]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2398s
########
2023-04-21 09:05:50,016 - [INFO] - [Epoch:189]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2389s
########
2023-04-21 09:06:04,429 - [INFO] - [Epoch:190]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2402s
########
2023-04-21 09:06:18,787 - [INFO] - [Epoch:191]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2393s
########
2023-04-21 09:06:33,136 - [INFO] - [Epoch:192]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2392s
########
2023-04-21 09:06:47,463 - [INFO] - [Epoch:193]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2388s
########
2023-04-21 09:07:01,827 - [INFO] - [Epoch:194]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2394s
########
2023-04-21 09:07:16,198 - [INFO] - [Epoch:195]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2395s
########
2023-04-21 09:07:30,560 - [INFO] - [Epoch:196]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2394s
########
2023-04-21 09:07:44,817 - [INFO] - [Epoch:197]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2376s
########
2023-04-21 09:07:59,155 - [INFO] - [Epoch:198]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2390s
########
2023-04-21 09:08:13,529 - [INFO] - [Epoch:199]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2396s
########
2023-04-21 09:08:27,776 - [INFO] - [Epoch:200]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2374s
2023-04-21 09:08:30,462 - [INFO] - [Epoch 200 valid]: MRR: Tail : 0.23157, Head : 0.14882, Avg : 0.1902
2023-04-21 09:08:30,463 - [INFO] - [Epoch 200 valid]: MR: Tail : 1052.1, Head : 1821.0, Avg : 1436.5
2023-04-21 09:08:30,549 - [INFO] - [Epoch 200]: Training Loss: 0.020639, Best Valid MRR: 0.1902


########
2023-04-21 09:08:44,838 - [INFO] - [Epoch:201]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2382s
2023-04-21 09:08:47,505 - [INFO] - [Epoch 201 valid]: MRR: Tail : 0.22965, Head : 0.14784, Avg : 0.18875
2023-04-21 09:08:47,506 - [INFO] - [Epoch 201 valid]: MR: Tail : 1074.6, Head : 1863.1, Avg : 1468.8
2023-04-21 09:08:47,506 - [INFO] - [Epoch 201]: Training Loss: 0.020639, Best Valid MRR: 0.1902


########
2023-04-21 09:09:01,834 - [INFO] - [Epoch:202]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2389s
2023-04-21 09:09:04,500 - [INFO] - [Epoch 202 valid]: MRR: Tail : 0.23169, Head : 0.14879, Avg : 0.19024
2023-04-21 09:09:04,500 - [INFO] - [Epoch 202 valid]: MR: Tail : 1054.4, Head : 1836.5, Avg : 1445.4
2023-04-21 09:09:04,598 - [INFO] - [Epoch 202]: Training Loss: 0.020638, Best Valid MRR: 0.19024


########
2023-04-21 09:09:18,862 - [INFO] - [Epoch:203]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2378s
2023-04-21 09:09:21,539 - [INFO] - [Epoch 203 valid]: MRR: Tail : 0.23162, Head : 0.14936, Avg : 0.19049
2023-04-21 09:09:21,539 - [INFO] - [Epoch 203 valid]: MR: Tail : 1078.8, Head : 1869.5, Avg : 1474.2
2023-04-21 09:09:21,635 - [INFO] - [Epoch 203]: Training Loss: 0.020638, Best Valid MRR: 0.19049


########
2023-04-21 09:09:36,029 - [INFO] - [Epoch:204]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2400s
2023-04-21 09:09:38,691 - [INFO] - [Epoch 204 valid]: MRR: Tail : 0.22929, Head : 0.14664, Avg : 0.18797
2023-04-21 09:09:38,692 - [INFO] - [Epoch 204 valid]: MR: Tail : 1055.2, Head : 1848.8, Avg : 1452.0
2023-04-21 09:09:38,692 - [INFO] - [Epoch 204]: Training Loss: 0.020636, Best Valid MRR: 0.19049


########
2023-04-21 09:09:53,048 - [INFO] - [Epoch:205]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2393s
2023-04-21 09:09:55,695 - [INFO] - [Epoch 205 valid]: MRR: Tail : 0.22653, Head : 0.14805, Avg : 0.18729
2023-04-21 09:09:55,696 - [INFO] - [Epoch 205 valid]: MR: Tail : 1067.6, Head : 1848.9, Avg : 1458.2
2023-04-21 09:09:55,696 - [INFO] - [Epoch 205]: Training Loss: 0.020636, Best Valid MRR: 0.19049


########
2023-04-21 09:10:10,037 - [INFO] - [Epoch:206]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2391s
2023-04-21 09:10:12,690 - [INFO] - [Epoch 206 valid]: MRR: Tail : 0.23008, Head : 0.14669, Avg : 0.18839
2023-04-21 09:10:12,691 - [INFO] - [Epoch 206 valid]: MR: Tail : 1059.0, Head : 1903.9, Avg : 1481.4
2023-04-21 09:10:12,691 - [INFO] - [Epoch 206]: Training Loss: 0.020637, Best Valid MRR: 0.19049


########
2023-04-21 09:10:27,025 - [INFO] - [Epoch:207]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2390s
2023-04-21 09:10:29,671 - [INFO] - [Epoch 207 valid]: MRR: Tail : 0.23001, Head : 0.14843, Avg : 0.18922
2023-04-21 09:10:29,671 - [INFO] - [Epoch 207 valid]: MR: Tail : 1081.3, Head : 1855.9, Avg : 1468.6
2023-04-21 09:10:29,672 - [INFO] - [Epoch 207]: Training Loss: 0.020636, Best Valid MRR: 0.19049


########
2023-04-21 09:10:43,980 - [INFO] - [Epoch:208]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2385s
2023-04-21 09:10:46,614 - [INFO] - [Epoch 208 valid]: MRR: Tail : 0.22892, Head : 0.14853, Avg : 0.18873
2023-04-21 09:10:46,614 - [INFO] - [Epoch 208 valid]: MR: Tail : 1046.5, Head : 1882.0, Avg : 1464.2
2023-04-21 09:10:46,615 - [INFO] - [Epoch 208]: Training Loss: 0.020637, Best Valid MRR: 0.19049


########
2023-04-21 09:11:00,984 - [INFO] - [Epoch:209]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2396s
2023-04-21 09:11:03,623 - [INFO] - [Epoch 209 valid]: MRR: Tail : 0.22664, Head : 0.14802, Avg : 0.18733
2023-04-21 09:11:03,623 - [INFO] - [Epoch 209 valid]: MR: Tail : 1065.6, Head : 1866.6, Avg : 1466.1
2023-04-21 09:11:03,623 - [INFO] - [Epoch 209]: Training Loss: 0.020636, Best Valid MRR: 0.19049


########
2023-04-21 09:11:17,971 - [INFO] - [Epoch:210]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2392s
2023-04-21 09:11:20,627 - [INFO] - [Epoch 210 valid]: MRR: Tail : 0.22944, Head : 0.14645, Avg : 0.18795
2023-04-21 09:11:20,627 - [INFO] - [Epoch 210 valid]: MR: Tail : 1059.4, Head : 1856.0, Avg : 1457.7
2023-04-21 09:11:20,627 - [INFO] - [Epoch 210]: Training Loss: 0.020634, Best Valid MRR: 0.19049


########
2023-04-21 09:11:34,852 - [INFO] - [Epoch:211]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2372s
2023-04-21 09:11:37,478 - [INFO] - [Epoch 211 valid]: MRR: Tail : 0.23155, Head : 0.14856, Avg : 0.19005
2023-04-21 09:11:37,479 - [INFO] - [Epoch 211 valid]: MR: Tail : 1099.1, Head : 1854.4, Avg : 1476.7
2023-04-21 09:11:37,479 - [INFO] - [Epoch 211]: Training Loss: 0.020633, Best Valid MRR: 0.19049


########
2023-04-21 09:11:51,603 - [INFO] - [Epoch:212]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2355s
2023-04-21 09:11:54,198 - [INFO] - [Epoch 212 valid]: MRR: Tail : 0.23188, Head : 0.15, Avg : 0.19094
2023-04-21 09:11:54,199 - [INFO] - [Epoch 212 valid]: MR: Tail : 1076.4, Head : 1819.3, Avg : 1447.8
2023-04-21 09:11:54,296 - [INFO] - [Epoch 212]: Training Loss: 0.020633, Best Valid MRR: 0.19094


########
2023-04-21 09:12:08,605 - [INFO] - [Epoch:213]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2386s
2023-04-21 09:12:11,210 - [INFO] - [Epoch 213 valid]: MRR: Tail : 0.22762, Head : 0.14528, Avg : 0.18645
2023-04-21 09:12:11,211 - [INFO] - [Epoch 213 valid]: MR: Tail : 1050.1, Head : 1867.1, Avg : 1458.6
2023-04-21 09:12:11,211 - [INFO] - [Epoch 213]: Training Loss: 0.020632, Best Valid MRR: 0.19094


########
2023-04-21 09:12:25,482 - [INFO] - [Epoch:214]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2379s
2023-04-21 09:12:28,076 - [INFO] - [Epoch 214 valid]: MRR: Tail : 0.22991, Head : 0.14854, Avg : 0.18922
2023-04-21 09:12:28,076 - [INFO] - [Epoch 214 valid]: MR: Tail : 1079.6, Head : 1848.4, Avg : 1464.0
2023-04-21 09:12:28,077 - [INFO] - [Epoch 214]: Training Loss: 0.020634, Best Valid MRR: 0.19094


########
2023-04-21 09:12:42,257 - [INFO] - [Epoch:215]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2364s
2023-04-21 09:12:44,851 - [INFO] - [Epoch 215 valid]: MRR: Tail : 0.2293, Head : 0.14769, Avg : 0.1885
2023-04-21 09:12:44,851 - [INFO] - [Epoch 215 valid]: MR: Tail : 1067.0, Head : 1852.8, Avg : 1459.9
2023-04-21 09:12:44,852 - [INFO] - [Epoch 215]: Training Loss: 0.020632, Best Valid MRR: 0.19094


########
2023-04-21 09:12:59,256 - [INFO] - [Epoch:216]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2401s
2023-04-21 09:13:01,973 - [INFO] - [Epoch 216 valid]: MRR: Tail : 0.22886, Head : 0.1465, Avg : 0.18768
2023-04-21 09:13:01,973 - [INFO] - [Epoch 216 valid]: MR: Tail : 1084.0, Head : 1853.0, Avg : 1468.5
2023-04-21 09:13:01,974 - [INFO] - [Epoch 216]: Training Loss: 0.020632, Best Valid MRR: 0.19094


########
2023-04-21 09:13:16,329 - [INFO] - [Epoch:217]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2393s
2023-04-21 09:13:19,019 - [INFO] - [Epoch 217 valid]: MRR: Tail : 0.22879, Head : 0.14825, Avg : 0.18852
2023-04-21 09:13:19,020 - [INFO] - [Epoch 217 valid]: MR: Tail : 1058.6, Head : 1833.3, Avg : 1445.9
2023-04-21 09:13:19,020 - [INFO] - [Epoch 217]: Training Loss: 0.020633, Best Valid MRR: 0.19094


########
2023-04-21 09:13:33,306 - [INFO] - [Epoch:218]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2382s
2023-04-21 09:13:35,957 - [INFO] - [Epoch 218 valid]: MRR: Tail : 0.23042, Head : 0.1468, Avg : 0.18861
2023-04-21 09:13:35,958 - [INFO] - [Epoch 218 valid]: MR: Tail : 1086.1, Head : 1843.2, Avg : 1464.6
2023-04-21 09:13:35,958 - [INFO] - [Epoch 218]: Training Loss: 0.020632, Best Valid MRR: 0.19094


########
2023-04-21 09:13:50,721 - [INFO] - [Epoch:219]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2461s
2023-04-21 09:13:53,390 - [INFO] - [Epoch 219 valid]: MRR: Tail : 0.23125, Head : 0.14802, Avg : 0.18963
2023-04-21 09:13:53,391 - [INFO] - [Epoch 219 valid]: MR: Tail : 1071.5, Head : 1876.1, Avg : 1473.8
2023-04-21 09:13:53,391 - [INFO] - [Epoch 219]: Training Loss: 0.02063, Best Valid MRR: 0.19094


########
2023-04-21 09:14:07,723 - [INFO] - [Epoch:220]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2389s
2023-04-21 09:14:10,393 - [INFO] - [Epoch 220 valid]: MRR: Tail : 0.23425, Head : 0.14794, Avg : 0.1911
2023-04-21 09:14:10,393 - [INFO] - [Epoch 220 valid]: MR: Tail : 1065.5, Head : 1810.7, Avg : 1438.1
2023-04-21 09:14:10,491 - [INFO] - [Epoch 220]: Training Loss: 0.020629, Best Valid MRR: 0.1911


########
2023-04-21 09:14:24,898 - [INFO] - [Epoch:221]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2402s
2023-04-21 09:14:27,545 - [INFO] - [Epoch 221 valid]: MRR: Tail : 0.23012, Head : 0.14544, Avg : 0.18778
2023-04-21 09:14:27,546 - [INFO] - [Epoch 221 valid]: MR: Tail : 1095.1, Head : 1864.2, Avg : 1479.7
2023-04-21 09:14:27,546 - [INFO] - [Epoch 221]: Training Loss: 0.020629, Best Valid MRR: 0.1911


########
2023-04-21 09:14:41,932 - [INFO] - [Epoch:222]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2398s
2023-04-21 09:14:44,626 - [INFO] - [Epoch 222 valid]: MRR: Tail : 0.23113, Head : 0.14685, Avg : 0.18899
2023-04-21 09:14:44,626 - [INFO] - [Epoch 222 valid]: MR: Tail : 1091.6, Head : 1837.3, Avg : 1464.5
2023-04-21 09:14:44,627 - [INFO] - [Epoch 222]: Training Loss: 0.02063, Best Valid MRR: 0.1911


########
2023-04-21 09:14:58,983 - [INFO] - [Epoch:223]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2393s
2023-04-21 09:15:01,639 - [INFO] - [Epoch 223 valid]: MRR: Tail : 0.23006, Head : 0.147, Avg : 0.18853
2023-04-21 09:15:01,639 - [INFO] - [Epoch 223 valid]: MR: Tail : 1076.6, Head : 1832.8, Avg : 1454.7
2023-04-21 09:15:01,639 - [INFO] - [Epoch 223]: Training Loss: 0.020629, Best Valid MRR: 0.1911


########
2023-04-21 09:15:15,935 - [INFO] - [Epoch:224]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2383s
2023-04-21 09:15:18,591 - [INFO] - [Epoch 224 valid]: MRR: Tail : 0.22529, Head : 0.14778, Avg : 0.18654
2023-04-21 09:15:18,592 - [INFO] - [Epoch 224 valid]: MR: Tail : 1069.7, Head : 1863.1, Avg : 1466.4
2023-04-21 09:15:18,592 - [INFO] - [Epoch 224]: Training Loss: 0.020628, Best Valid MRR: 0.1911


########
2023-04-21 09:15:32,893 - [INFO] - [Epoch:225]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2384s
2023-04-21 09:15:35,545 - [INFO] - [Epoch 225 valid]: MRR: Tail : 0.23166, Head : 0.14888, Avg : 0.19027
2023-04-21 09:15:35,545 - [INFO] - [Epoch 225 valid]: MR: Tail : 1044.0, Head : 1830.4, Avg : 1437.2
2023-04-21 09:15:35,545 - [INFO] - [Epoch 225]: Training Loss: 0.020629, Best Valid MRR: 0.1911


########
2023-04-21 09:15:49,909 - [INFO] - [Epoch:226]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2395s
2023-04-21 09:15:52,570 - [INFO] - [Epoch 226 valid]: MRR: Tail : 0.2317, Head : 0.1453, Avg : 0.1885
2023-04-21 09:15:52,570 - [INFO] - [Epoch 226 valid]: MR: Tail : 1087.3, Head : 1858.8, Avg : 1473.0
2023-04-21 09:15:52,570 - [INFO] - [Epoch 226]: Training Loss: 0.020629, Best Valid MRR: 0.1911


########
2023-04-21 09:16:06,883 - [INFO] - [Epoch:227]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2386s
2023-04-21 09:16:09,537 - [INFO] - [Epoch 227 valid]: MRR: Tail : 0.23585, Head : 0.15006, Avg : 0.19295
2023-04-21 09:16:09,537 - [INFO] - [Epoch 227 valid]: MR: Tail : 1040.3, Head : 1865.1, Avg : 1452.7
2023-04-21 09:16:09,631 - [INFO] - [Epoch 227]: Training Loss: 0.020629, Best Valid MRR: 0.19295


########
2023-04-21 09:16:23,988 - [INFO] - [Epoch:228]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2393s
2023-04-21 09:16:26,631 - [INFO] - [Epoch 228 valid]: MRR: Tail : 0.23122, Head : 0.14888, Avg : 0.19005
2023-04-21 09:16:26,631 - [INFO] - [Epoch 228 valid]: MR: Tail : 1076.9, Head : 1845.4, Avg : 1461.2
2023-04-21 09:16:26,632 - [INFO] - [Epoch 228]: Training Loss: 0.020628, Best Valid MRR: 0.19295


########
2023-04-21 09:16:40,952 - [INFO] - [Epoch:229]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2387s
2023-04-21 09:16:43,607 - [INFO] - [Epoch 229 valid]: MRR: Tail : 0.22681, Head : 0.14691, Avg : 0.18686
2023-04-21 09:16:43,607 - [INFO] - [Epoch 229 valid]: MR: Tail : 1095.5, Head : 1831.2, Avg : 1463.4
2023-04-21 09:16:43,607 - [INFO] - [Epoch 229]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:16:57,908 - [INFO] - [Epoch:230]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2384s
2023-04-21 09:17:00,562 - [INFO] - [Epoch 230 valid]: MRR: Tail : 0.23023, Head : 0.14731, Avg : 0.18877
2023-04-21 09:17:00,562 - [INFO] - [Epoch 230 valid]: MR: Tail : 1075.6, Head : 1837.1, Avg : 1456.4
2023-04-21 09:17:00,562 - [INFO] - [Epoch 230]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:17:14,842 - [INFO] - [Epoch:231]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2381s
2023-04-21 09:17:17,481 - [INFO] - [Epoch 231 valid]: MRR: Tail : 0.23003, Head : 0.14644, Avg : 0.18824
2023-04-21 09:17:17,481 - [INFO] - [Epoch 231 valid]: MR: Tail : 1074.3, Head : 1811.2, Avg : 1442.8
2023-04-21 09:17:17,481 - [INFO] - [Epoch 231]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:17:31,793 - [INFO] - [Epoch:232]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2386s
2023-04-21 09:17:34,447 - [INFO] - [Epoch 232 valid]: MRR: Tail : 0.23162, Head : 0.14559, Avg : 0.18861
2023-04-21 09:17:34,447 - [INFO] - [Epoch 232 valid]: MR: Tail : 1081.9, Head : 1852.0, Avg : 1467.0
2023-04-21 09:17:34,447 - [INFO] - [Epoch 232]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:17:48,705 - [INFO] - [Epoch:233]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2377s
2023-04-21 09:17:51,342 - [INFO] - [Epoch 233 valid]: MRR: Tail : 0.2302, Head : 0.14729, Avg : 0.18875
2023-04-21 09:17:51,343 - [INFO] - [Epoch 233 valid]: MR: Tail : 1068.5, Head : 1853.9, Avg : 1461.2
2023-04-21 09:17:51,343 - [INFO] - [Epoch 233]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:18:05,639 - [INFO] - [Epoch:234]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2383s
2023-04-21 09:18:08,305 - [INFO] - [Epoch 234 valid]: MRR: Tail : 0.22859, Head : 0.14771, Avg : 0.18815
2023-04-21 09:18:08,306 - [INFO] - [Epoch 234 valid]: MR: Tail : 1072.1, Head : 1840.5, Avg : 1456.3
2023-04-21 09:18:08,306 - [INFO] - [Epoch 234]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:18:22,546 - [INFO] - [Epoch:235]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2374s
2023-04-21 09:18:25,157 - [INFO] - [Epoch 235 valid]: MRR: Tail : 0.23073, Head : 0.1475, Avg : 0.18912
2023-04-21 09:18:25,157 - [INFO] - [Epoch 235 valid]: MR: Tail : 1078.0, Head : 1824.2, Avg : 1451.1
2023-04-21 09:18:25,157 - [INFO] - [Epoch 235]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:18:38,908 - [INFO] - [Epoch:236]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2292s
2023-04-21 09:18:41,537 - [INFO] - [Epoch 236 valid]: MRR: Tail : 0.233, Head : 0.14402, Avg : 0.18851
2023-04-21 09:18:41,538 - [INFO] - [Epoch 236 valid]: MR: Tail : 1069.4, Head : 1831.8, Avg : 1450.6
2023-04-21 09:18:41,538 - [INFO] - [Epoch 236]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:18:55,807 - [INFO] - [Epoch:237]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2379s
2023-04-21 09:18:58,448 - [INFO] - [Epoch 237 valid]: MRR: Tail : 0.2312, Head : 0.14784, Avg : 0.18952
2023-04-21 09:18:58,449 - [INFO] - [Epoch 237 valid]: MR: Tail : 1056.6, Head : 1805.3, Avg : 1431.0
2023-04-21 09:18:58,449 - [INFO] - Gamma decay on saturation, updated value of gamma: 35
2023-04-21 09:18:58,449 - [INFO] - [Epoch 237]: Training Loss: 0.020626, Best Valid MRR: 0.19295


########
2023-04-21 09:19:10,852 - [INFO] - [Epoch:238]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2068s
2023-04-21 09:19:13,491 - [INFO] - [Epoch 238 valid]: MRR: Tail : 0.23912, Head : 0.15123, Avg : 0.19517
2023-04-21 09:19:13,491 - [INFO] - [Epoch 238 valid]: MR: Tail : 1016.2, Head : 1756.9, Avg : 1386.6
2023-04-21 09:19:13,584 - [INFO] - [Epoch 238]: Training Loss: 0.020664, Best Valid MRR: 0.19517


########
2023-04-21 09:19:27,872 - [INFO] - [Epoch:239]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2382s
2023-04-21 09:19:30,511 - [INFO] - [Epoch 239 valid]: MRR: Tail : 0.23823, Head : 0.14976, Avg : 0.19399
2023-04-21 09:19:30,512 - [INFO] - [Epoch 239 valid]: MR: Tail : 1000.4, Head : 1755.8, Avg : 1378.1
2023-04-21 09:19:30,512 - [INFO] - [Epoch 239]: Training Loss: 0.020632, Best Valid MRR: 0.19517


########
2023-04-21 09:19:44,800 - [INFO] - [Epoch:240]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2382s
2023-04-21 09:19:47,434 - [INFO] - [Epoch 240 valid]: MRR: Tail : 0.23689, Head : 0.14859, Avg : 0.19274
2023-04-21 09:19:47,434 - [INFO] - [Epoch 240 valid]: MR: Tail : 996.66, Head : 1730.3, Avg : 1363.5
2023-04-21 09:19:47,434 - [INFO] - [Epoch 240]: Training Loss: 0.020627, Best Valid MRR: 0.19517


########
2023-04-21 09:20:01,803 - [INFO] - [Epoch:241]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2395s
2023-04-21 09:20:04,450 - [INFO] - [Epoch 241 valid]: MRR: Tail : 0.23237, Head : 0.14777, Avg : 0.19007
2023-04-21 09:20:04,450 - [INFO] - [Epoch 241 valid]: MR: Tail : 1026.1, Head : 1719.7, Avg : 1372.9
2023-04-21 09:20:04,450 - [INFO] - [Epoch 241]: Training Loss: 0.020626, Best Valid MRR: 0.19517


########
2023-04-21 09:20:18,726 - [INFO] - [Epoch:242]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2380s
2023-04-21 09:20:21,367 - [INFO] - [Epoch 242 valid]: MRR: Tail : 0.23368, Head : 0.14896, Avg : 0.19132
2023-04-21 09:20:21,367 - [INFO] - [Epoch 242 valid]: MR: Tail : 1007.6, Head : 1768.1, Avg : 1387.8
2023-04-21 09:20:21,367 - [INFO] - [Epoch 242]: Training Loss: 0.020624, Best Valid MRR: 0.19517


########
2023-04-21 09:20:35,707 - [INFO] - [Epoch:243]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2391s
2023-04-21 09:20:38,330 - [INFO] - [Epoch 243 valid]: MRR: Tail : 0.23391, Head : 0.14711, Avg : 0.19051
2023-04-21 09:20:38,331 - [INFO] - [Epoch 243 valid]: MR: Tail : 1022.4, Head : 1720.7, Avg : 1371.5
2023-04-21 09:20:38,331 - [INFO] - [Epoch 243]: Training Loss: 0.020623, Best Valid MRR: 0.19517


########
2023-04-21 09:20:52,651 - [INFO] - [Epoch:244]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2387s
2023-04-21 09:20:55,289 - [INFO] - [Epoch 244 valid]: MRR: Tail : 0.234, Head : 0.14766, Avg : 0.19083
2023-04-21 09:20:55,289 - [INFO] - [Epoch 244 valid]: MR: Tail : 1015.9, Head : 1757.6, Avg : 1386.7
2023-04-21 09:20:55,289 - [INFO] - [Epoch 244]: Training Loss: 0.020624, Best Valid MRR: 0.19517


########
2023-04-21 09:21:09,632 - [INFO] - [Epoch:245]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2391s
2023-04-21 09:21:12,253 - [INFO] - [Epoch 245 valid]: MRR: Tail : 0.23168, Head : 0.14696, Avg : 0.18932
2023-04-21 09:21:12,254 - [INFO] - [Epoch 245 valid]: MR: Tail : 997.91, Head : 1740.6, Avg : 1369.2
2023-04-21 09:21:12,254 - [INFO] - [Epoch 245]: Training Loss: 0.020623, Best Valid MRR: 0.19517


########
2023-04-21 09:21:26,569 - [INFO] - [Epoch:246]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2386s
2023-04-21 09:21:29,217 - [INFO] - [Epoch 246 valid]: MRR: Tail : 0.23348, Head : 0.14641, Avg : 0.18994
2023-04-21 09:21:29,218 - [INFO] - [Epoch 246 valid]: MR: Tail : 1022.1, Head : 1756.7, Avg : 1389.4
2023-04-21 09:21:29,218 - [INFO] - [Epoch 246]: Training Loss: 0.020622, Best Valid MRR: 0.19517


########
2023-04-21 09:21:43,568 - [INFO] - [Epoch:247]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2392s
2023-04-21 09:21:46,214 - [INFO] - [Epoch 247 valid]: MRR: Tail : 0.23025, Head : 0.14493, Avg : 0.18759
2023-04-21 09:21:46,215 - [INFO] - [Epoch 247 valid]: MR: Tail : 1009.8, Head : 1739.5, Avg : 1374.7
2023-04-21 09:21:46,215 - [INFO] - [Epoch 247]: Training Loss: 0.020623, Best Valid MRR: 0.19517


########
2023-04-21 09:22:00,518 - [INFO] - [Epoch:248]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2385s
2023-04-21 09:22:03,157 - [INFO] - [Epoch 248 valid]: MRR: Tail : 0.23214, Head : 0.14882, Avg : 0.19048
2023-04-21 09:22:03,157 - [INFO] - [Epoch 248 valid]: MR: Tail : 1005.3, Head : 1740.8, Avg : 1373.1
2023-04-21 09:22:03,158 - [INFO] - Gamma decay on saturation, updated value of gamma: 30
2023-04-21 09:22:03,158 - [INFO] - [Epoch 248]: Training Loss: 0.020624, Best Valid MRR: 0.19517


########
2023-04-21 09:22:17,499 - [INFO] - [Epoch:249]:  Training Loss:0.02068

Time cost in one epoch for training: 0.2391s
2023-04-21 09:22:20,172 - [INFO] - [Epoch 249 valid]: MRR: Tail : 0.23741, Head : 0.14842, Avg : 0.19291
2023-04-21 09:22:20,172 - [INFO] - [Epoch 249 valid]: MR: Tail : 1003.6, Head : 1692.5, Avg : 1348.0
2023-04-21 09:22:20,172 - [INFO] - [Epoch 249]: Training Loss: 0.020676, Best Valid MRR: 0.19517


########
2023-04-21 09:22:34,365 - [INFO] - [Epoch:250]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2366s
2023-04-21 09:22:37,017 - [INFO] - [Epoch 250 valid]: MRR: Tail : 0.23175, Head : 0.14823, Avg : 0.18999
2023-04-21 09:22:37,018 - [INFO] - [Epoch 250 valid]: MR: Tail : 955.38, Head : 1650.4, Avg : 1302.9
2023-04-21 09:22:37,018 - [INFO] - [Epoch 250]: Training Loss: 0.020641, Best Valid MRR: 0.19517


########
2023-04-21 09:22:51,294 - [INFO] - [Epoch:251]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2380s
2023-04-21 09:22:53,934 - [INFO] - [Epoch 251 valid]: MRR: Tail : 0.23348, Head : 0.1482, Avg : 0.19084
2023-04-21 09:22:53,934 - [INFO] - [Epoch 251 valid]: MR: Tail : 956.75, Head : 1668.5, Avg : 1312.6
2023-04-21 09:22:53,934 - [INFO] - [Epoch 251]: Training Loss: 0.020634, Best Valid MRR: 0.19517


########
2023-04-21 09:23:08,307 - [INFO] - [Epoch:252]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2396s
2023-04-21 09:23:10,973 - [INFO] - [Epoch 252 valid]: MRR: Tail : 0.23009, Head : 0.14462, Avg : 0.18736
2023-04-21 09:23:10,973 - [INFO] - [Epoch 252 valid]: MR: Tail : 945.13, Head : 1602.8, Avg : 1273.9
2023-04-21 09:23:10,973 - [INFO] - [Epoch 252]: Training Loss: 0.02063, Best Valid MRR: 0.19517


########
2023-04-21 09:23:25,301 - [INFO] - [Epoch:253]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2389s
2023-04-21 09:23:27,942 - [INFO] - [Epoch 253 valid]: MRR: Tail : 0.2305, Head : 0.14602, Avg : 0.18826
2023-04-21 09:23:27,942 - [INFO] - [Epoch 253 valid]: MR: Tail : 931.13, Head : 1628.1, Avg : 1279.6
2023-04-21 09:23:27,942 - [INFO] - [Epoch 253]: Training Loss: 0.020627, Best Valid MRR: 0.19517


########
2023-04-21 09:23:42,260 - [INFO] - [Epoch:254]:  Training Loss:0.02063

Time cost in one epoch for training: 0.2387s
2023-04-21 09:23:44,895 - [INFO] - [Epoch 254 valid]: MRR: Tail : 0.23066, Head : 0.14548, Avg : 0.18807
2023-04-21 09:23:44,895 - [INFO] - [Epoch 254 valid]: MR: Tail : 941.07, Head : 1622.2, Avg : 1281.6
2023-04-21 09:23:44,896 - [INFO] - [Epoch 254]: Training Loss: 0.020625, Best Valid MRR: 0.19517


########
2023-04-21 09:23:59,169 - [INFO] - [Epoch:255]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2380s
2023-04-21 09:24:01,808 - [INFO] - [Epoch 255 valid]: MRR: Tail : 0.22993, Head : 0.14681, Avg : 0.18837
2023-04-21 09:24:01,808 - [INFO] - [Epoch 255 valid]: MR: Tail : 950.49, Head : 1635.7, Avg : 1293.1
2023-04-21 09:24:01,808 - [INFO] - [Epoch 255]: Training Loss: 0.020624, Best Valid MRR: 0.19517


########
2023-04-21 09:24:16,126 - [INFO] - [Epoch:256]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2387s
2023-04-21 09:24:18,748 - [INFO] - [Epoch 256 valid]: MRR: Tail : 0.22864, Head : 0.14407, Avg : 0.18635
2023-04-21 09:24:18,748 - [INFO] - [Epoch 256 valid]: MR: Tail : 927.13, Head : 1638.7, Avg : 1282.9
2023-04-21 09:24:18,749 - [INFO] - [Epoch 256]: Training Loss: 0.020623, Best Valid MRR: 0.19517


########
2023-04-21 09:24:32,898 - [INFO] - [Epoch:257]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2359s
2023-04-21 09:24:35,536 - [INFO] - [Epoch 257 valid]: MRR: Tail : 0.23012, Head : 0.14638, Avg : 0.18825
2023-04-21 09:24:35,537 - [INFO] - [Epoch 257 valid]: MR: Tail : 951.55, Head : 1658.1, Avg : 1304.8
2023-04-21 09:24:35,537 - [INFO] - [Epoch 257]: Training Loss: 0.020624, Best Valid MRR: 0.19517


########
2023-04-21 09:24:49,864 - [INFO] - [Epoch:258]:  Training Loss:0.02062

Time cost in one epoch for training: 0.2388s
2023-04-21 09:24:52,516 - [INFO] - [Epoch 258 valid]: MRR: Tail : 0.23055, Head : 0.14578, Avg : 0.18817
2023-04-21 09:24:52,517 - [INFO] - [Epoch 258 valid]: MR: Tail : 971.07, Head : 1649.3, Avg : 1310.2
2023-04-21 09:24:52,517 - [INFO] - Gamma decay on saturation, updated value of gamma: 25
2023-04-21 09:24:52,517 - [INFO] - [Epoch 258]: Training Loss: 0.020623, Best Valid MRR: 0.19517


########
2023-04-21 09:25:06,889 - [INFO] - [Epoch:259]:  Training Loss:0.02069

Time cost in one epoch for training: 0.2396s
2023-04-21 09:25:09,535 - [INFO] - [Epoch 259 valid]: MRR: Tail : 0.2317, Head : 0.14639, Avg : 0.18905
2023-04-21 09:25:09,536 - [INFO] - [Epoch 259 valid]: MR: Tail : 952.71, Head : 1621.4, Avg : 1287.0
2023-04-21 09:25:09,536 - [INFO] - [Epoch 259]: Training Loss: 0.020695, Best Valid MRR: 0.19517


########
2023-04-21 09:25:23,905 - [INFO] - [Epoch:260]:  Training Loss:0.02066

Time cost in one epoch for training: 0.2396s
2023-04-21 09:25:26,567 - [INFO] - [Epoch 260 valid]: MRR: Tail : 0.23051, Head : 0.14362, Avg : 0.18707
2023-04-21 09:25:26,568 - [INFO] - [Epoch 260 valid]: MR: Tail : 932.71, Head : 1609.5, Avg : 1271.1
2023-04-21 09:25:26,568 - [INFO] - [Epoch 260]: Training Loss: 0.02066, Best Valid MRR: 0.19517


########
2023-04-21 09:25:40,859 - [INFO] - [Epoch:261]:  Training Loss:0.02065

Time cost in one epoch for training: 0.2383s
2023-04-21 09:25:43,496 - [INFO] - [Epoch 261 valid]: MRR: Tail : 0.22968, Head : 0.14417, Avg : 0.18693
2023-04-21 09:25:43,496 - [INFO] - [Epoch 261 valid]: MR: Tail : 907.9, Head : 1592.1, Avg : 1250.0
2023-04-21 09:25:43,497 - [INFO] - [Epoch 261]: Training Loss: 0.020649, Best Valid MRR: 0.19517


########
2023-04-21 09:25:57,791 - [INFO] - [Epoch:262]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2383s
2023-04-21 09:26:00,434 - [INFO] - [Epoch 262 valid]: MRR: Tail : 0.23019, Head : 0.14239, Avg : 0.18629
2023-04-21 09:26:00,434 - [INFO] - [Epoch 262 valid]: MR: Tail : 886.24, Head : 1569.4, Avg : 1227.8
2023-04-21 09:26:00,434 - [INFO] - [Epoch 262]: Training Loss: 0.020642, Best Valid MRR: 0.19517


########
2023-04-21 09:26:14,746 - [INFO] - [Epoch:263]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2386s
2023-04-21 09:26:17,382 - [INFO] - [Epoch 263 valid]: MRR: Tail : 0.22781, Head : 0.14385, Avg : 0.18583
2023-04-21 09:26:17,383 - [INFO] - [Epoch 263 valid]: MR: Tail : 881.19, Head : 1545.8, Avg : 1213.5
2023-04-21 09:26:17,383 - [INFO] - [Epoch 263]: Training Loss: 0.020637, Best Valid MRR: 0.19517


########
2023-04-21 09:26:31,672 - [INFO] - [Epoch:264]:  Training Loss:0.02064

Time cost in one epoch for training: 0.2382s
2023-04-21 09:26:34,318 - [INFO] - [Epoch 264 valid]: MRR: Tail : 0.22768, Head : 0.14308, Avg : 0.18538
2023-04-21 09:26:34,319 - [INFO] - [Epoch 264 valid]: MR: Tail : 890.61, Head : 1574.1, Avg : 1232.4
2023-04-21 09:26:34,319 - [INFO] - Early Stopping!!
2023-04-21 09:26:34,319 - [INFO] - Loading best model, Evaluating on Test data
2023-04-21 09:26:37,022 - [INFO] - [Epoch 264 test]: MRR: Tail : 0.25279, Head : 0.15848, Avg : 0.20564
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: MR: Tail : 980.73, Head : 1750.7, Avg : 1365.7
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: Hit@1: Tail : 0.1666, Head : 0.10077, Avg : 0.13368
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: Hit@2: Tail : 0.22758, Head : 0.14459, Avg : 0.18609
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: Hit@3: Tail : 0.26898, Head : 0.17145, Avg : 0.22021
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: Hit@4: Tail : 0.30473, Head : 0.19184, Avg : 0.24828
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: Hit@5: Tail : 0.33461, Head : 0.21062, Avg : 0.27262
2023-04-21 09:26:37,023 - [INFO] - [Epoch 264 test]: Hit@6: Tail : 0.35642, Head : 0.22173, Avg : 0.28908
2023-04-21 09:26:37,024 - [INFO] - [Epoch 264 test]: Hit@7: Tail : 0.37803, Head : 0.23304, Avg : 0.30553
2023-04-21 09:26:37,024 - [INFO] - [Epoch 264 test]: Hit@8: Tail : 0.40287, Head : 0.24253, Avg : 0.3227
2023-04-21 09:26:37,024 - [INFO] - [Epoch 264 test]: Hit@9: Tail : 0.42104, Head : 0.25242, Avg : 0.33673
2023-04-21 09:26:37,024 - [INFO] - [Epoch 264 test]: Hit@10: Tail : 0.43821, Head : 0.26393, Avg : 0.35107
2023-04-21 09:26:37,024 - [INFO] - Test Avg MRR: 0.20564